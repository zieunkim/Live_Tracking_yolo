{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dd80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_16', 'yolo_23']\n",
      "422 165 513 543\n",
      "435 158 465 551\n",
      "451 154 439 558\n",
      "471 149 411 569\n",
      "468 133 398 597\n",
      "458 136 427 600\n",
      "417 166 409 572\n",
      "467 157 392 584\n",
      "432 154 390 575\n",
      "453 163 396 564\n",
      "421 150 395 601\n",
      "419 177 379 556\n",
      "363 174 430 563\n",
      "360 183 405 550\n",
      "317 203 398 515\n",
      "379 198 346 531\n",
      "307 182 401 564\n",
      "382 188 342 549\n",
      "302 184 403 552\n",
      "307 195 382 540\n",
      "317 198 371 535\n",
      "317 194 365 541\n",
      "317 196 345 545\n",
      "313 197 338 546\n",
      "320 228 323 483\n",
      "330 252 316 473\n",
      "309 251 347 443\n",
      "313 257 354 465\n",
      "327 257 327 431\n",
      "331 251 338 480\n",
      "317 255 339 434\n",
      "322 249 359 490\n",
      "316 238 350 505\n",
      "318 243 324 462\n",
      "326 240 331 499\n",
      "332 247 320 489\n",
      "339 245 314 500\n",
      "342 243 310 508\n",
      "333 248 312 502\n",
      "337 252 312 498\n",
      "332 247 306 500\n",
      "324 249 310 491\n",
      "326 249 305 494\n",
      "324 257 300 477\n",
      "305 244 326 498\n",
      "316 244 297 501\n",
      "247 237 322 519\n",
      "303 251 316 489\n",
      "241 236 331 521\n",
      "305 256 303 480\n",
      "256 239 308 516\n",
      "301 260 307 470\n",
      "326 258 264 480\n",
      "326 251 289 487\n",
      "326 259 284 477\n",
      "313 264 309 471\n",
      "298 251 339 485\n",
      "289 257 355 482\n",
      "290 267 344 466\n",
      "224 269 357 472\n",
      "287 279 331 447\n",
      "241 275 329 452\n",
      "276 282 327 438\n",
      "231 271 310 464\n",
      "220 265 305 471\n",
      "223 259 289 476\n",
      "227 259 252 416\n",
      "214 263 282 467\n",
      "143 253 321 494\n",
      "179 264 321 471\n",
      "122 242 328 447\n",
      "128 260 330 478\n",
      "116 224 318 486\n",
      "117 249 320 501\n",
      "124 231 302 470\n",
      "124 241 302 517\n",
      "121 228 300 481\n",
      "118 245 306 516\n",
      "105 240 322 455\n",
      "113 248 312 513\n",
      "103 244 322 446\n",
      "109 252 317 506\n",
      "110 230 314 478\n",
      "116 247 309 512\n",
      "123 246 308 441\n",
      "123 241 309 520\n",
      "114 223 319 484\n",
      "115 245 328 507\n",
      "116 247 332 437\n",
      "119 255 335 482\n",
      "138 260 326 479\n",
      "178 265 316 471\n",
      "197 259 307 478\n",
      "218 258 296 485\n",
      "241 261 297 484\n",
      "264 273 282 381\n",
      "248 267 311 470\n",
      "289 274 304 458\n",
      "312 276 291 460\n",
      "323 275 295 462\n",
      "315 282 325 458\n",
      "328 273 300 475\n",
      "349 277 296 466\n",
      "339 273 311 469\n",
      "366 281 293 452\n",
      "405 275 281 461\n",
      "376 290 280 438\n",
      "404 276 287 469\n",
      "371 288 287 435\n",
      "409 278 296 456\n",
      "409 270 327 462\n",
      "399 269 351 469\n",
      "428 254 305 429\n",
      "420 263 330 472\n",
      "425 252 313 437\n",
      "427 259 327 474\n",
      "429 253 337 483\n",
      "427 269 342 397\n",
      "439 253 337 479\n",
      "515 287 289 429\n",
      "524 257 299 419\n",
      "520 272 306 448\n",
      "543 253 306 425\n",
      "548 265 300 447\n",
      "562 234 297 449\n",
      "555 275 320 439\n",
      "587 231 287 471\n",
      "617 232 277 469\n",
      "569 255 320 471\n",
      "632 216 264 501\n",
      "612 233 308 516\n",
      "631 194 282 550\n",
      "614 232 311 514\n",
      "626 197 293 542\n",
      "622 202 298 531\n",
      "601 221 332 533\n",
      "625 198 282 536\n",
      "621 200 290 534\n",
      "611 196 316 543\n",
      "621 199 293 534\n",
      "616 186 316 559\n",
      "630 193 314 544\n",
      "635 202 328 524\n",
      "630 204 332 515\n",
      "646 200 328 514\n",
      "669 203 334 520\n",
      "704 204 339 521\n",
      "685 206 306 515\n",
      "712 197 329 539\n",
      "705 265 337 453\n",
      "722 170 332 592\n",
      "706 249 351 484\n",
      "731 172 341 587\n",
      "720 256 343 472\n",
      "736 178 360 567\n",
      "738 168 352 582\n",
      "726 261 360 458\n",
      "742 181 343 561\n",
      "729 261 350 460\n",
      "736 194 349 541\n",
      "726 265 353 454\n",
      "737 178 337 569\n",
      "730 263 339 460\n",
      "730 173 343 579\n",
      "714 255 351 474\n",
      "713 172 345 586\n",
      "676 204 322 516\n",
      "712 197 325 538\n",
      "671 203 327 518\n",
      "713 201 310 522\n",
      "648 195 330 528\n",
      "632 195 322 529\n",
      "635 194 324 537\n",
      "641 187 281 552\n",
      "629 191 282 546\n",
      "610 231 317 515\n",
      "635 206 257 520\n",
      "636 219 250 492\n",
      "634 216 253 489\n",
      "635 220 250 485\n",
      "615 232 295 515\n",
      "637 218 245 493\n",
      "619 236 296 507\n",
      "637 202 257 531\n",
      "633 207 265 520\n",
      "626 204 283 527\n",
      "633 208 265 521\n",
      "607 230 257 471\n",
      "636 224 248 484\n",
      "609 229 251 473\n",
      "633 225 252 479\n",
      "591 223 281 488\n",
      "618 227 281 480\n",
      "591 229 280 478\n",
      "613 239 285 455\n",
      "571 257 316 467\n",
      "572 235 294 456\n",
      "564 263 315 451\n",
      "562 229 286 471\n",
      "551 272 314 439\n",
      "534 241 310 458\n",
      "535 267 309 449\n",
      "522 237 273 457\n",
      "519 282 282 435\n",
      "457 254 307 421\n",
      "449 275 329 439\n",
      "430 236 313 464\n",
      "424 267 329 451\n",
      "411 237 319 466\n",
      "401 250 336 473\n",
      "407 247 317 446\n",
      "400 251 321 476\n",
      "410 243 277 447\n",
      "395 247 310 488\n",
      "346 246 332 442\n",
      "407 234 282 459\n",
      "355 236 316 467\n",
      "404 235 289 469\n",
      "341 234 330 512\n",
      "340 237 332 464\n",
      "341 253 329 477\n",
      "333 231 328 475\n",
      "341 240 318 501\n",
      "326 230 330 476\n",
      "333 241 319 499\n",
      "331 217 320 504\n",
      "333 234 317 514\n",
      "324 197 320 540\n",
      "327 238 316 508\n",
      "322 198 322 538\n",
      "331 239 310 505\n",
      "328 192 312 548\n",
      "329 238 314 505\n",
      "321 209 317 514\n",
      "328 243 312 500\n",
      "301 198 346 536\n",
      "281 202 350 522\n",
      "272 203 352 515\n",
      "232 201 358 515\n",
      "275 212 330 493\n",
      "227 191 344 546\n",
      "208 197 344 537\n",
      "206 250 352 478\n",
      "174 204 358 523\n",
      "169 237 372 505\n",
      "115 199 376 524\n",
      "168 207 348 511\n",
      "115 177 364 564\n",
      "113 179 349 560\n",
      "112 182 337 561\n",
      "95 240 354 501\n",
      "110 192 322 547\n",
      "101 239 334 503\n",
      "107 199 324 536\n",
      "101 234 328 514\n",
      "90 212 342 512\n",
      "90 221 337 536\n",
      "100 214 330 510\n",
      "95 218 329 539\n",
      "87 220 335 502\n",
      "89 225 326 527\n",
      "80 220 341 504\n",
      "81 226 334 525\n",
      "85 223 338 498\n",
      "82 231 338 517\n",
      "86 231 338 483\n",
      "83 224 334 531\n",
      "85 238 326 468\n",
      "73 230 341 521\n",
      "76 237 334 468\n",
      "74 240 337 504\n",
      "82 241 328 459\n",
      "85 233 321 512\n",
      "86 232 311 467\n",
      "74 239 320 451\n",
      "43 260 372 466\n",
      "19 230 347 472\n",
      "16 242 352 497\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 127>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m     image \u001b[38;5;241m=\u001b[39m img[:, \u001b[38;5;241m440\u001b[39m:\u001b[38;5;241m840\u001b[39m]\n\u001b[1;32m    172\u001b[0m j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 174\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautocrop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m key_pressed \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_pressed \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:967: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import math\n",
    "import sys \n",
    "from time import time\n",
    "\n",
    "min_confidence = 0.4 # bounding box 임계값\n",
    "t= 0\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "\n",
    "def detectAndDisplay(frame):\n",
    "    img = frame\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (384, 384), (0, 0, 0), True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # 탐지한 객체의 클래스 예측 \n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # 원하는 class id 입력 ex) person == 1, cat ==16 / coco.names의 id에서 -1 해서 넣어주면 됨\n",
    "            if class_id == 0 and confidence > min_confidence:\n",
    "                # 탐지한 객체 boxing\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "               \n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                print(x, y, w, h)\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = \"{}: {:.2f}\".format(classes[class_ids[i]], confidences[i]*100)\n",
    "            color = colors[i] #-- 경계 상자 컬러 설정 / 단일 생상 사용시 (255,255,255)사용(B,G,R)\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "#--------------------------------------------------------------------------------------------\n",
    "# yolo 포맷 및 클래스명 불러오기\n",
    "model_file = 'yolov3-tiny.weights'# 모델\n",
    "config_file = 'yolov3-tiny.cfg'# 모델\n",
    "\n",
    "net = cv2.dnn.readNet(model_file, config_file)\n",
    "\n",
    "# 클래스(names파일)\n",
    "classes = []\n",
    "with open(\"./coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "print(output_layers)\n",
    "\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# 카메라 input\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened:\n",
    "    print('--(!)Error opening video capture')\n",
    "    sys.exit(1)\n",
    "\n",
    "Ghh = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "Gww = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "Ghh, Gww = int(Ghh), int(Gww)\n",
    "\n",
    "#x, y, w, h = rect\n",
    "x = int(Gww*0.1)\n",
    "y = int(Ghh*0.1)\n",
    "w = int(Gww*0.8)\n",
    "h = int(Ghh*0.8)\n",
    "\n",
    "# 필요 변수 선언\n",
    "i = 0 # frame count & 저장 리스트 비교용\n",
    "tmp = 0 # 첫번째 detection 구분\n",
    "notcnt = 0 # 아무것도 검출이 안되는 상황 대비, 일정 카운트 이상일 시 원본 frame 크기로 변경\n",
    "case_not = 0 # 검출이 안되다가 갑자기 검출될 시 발생하는 예외 제거\n",
    "j = 1 # 프레임 별 시간 계산용\n",
    "time_tmp = 0 # 시간 cnt 시작\n",
    "\n",
    "t1 = 0.0\n",
    "\n",
    "# 프레임 간 좌표 계산을 위한 저장용 list 생성, 초기값 append\n",
    "PX = []\n",
    "PY = []\n",
    "X_min = []\n",
    "X_max = []\n",
    "Y_min = []\n",
    "Y_max = []\n",
    "X_min.append(x)\n",
    "X_max.append(x+w)\n",
    "Y_min.append(y)\n",
    "Y_max.append(y+h)\n",
    "\n",
    "PX.append((X_max[i] + X_min[i])/2)\n",
    "PY.append((Y_max[i] + Y_min[i])/2)\n",
    "\n",
    "\n",
    "tt_i = time()\n",
    "while cap.isOpened():\n",
    "    tt0 = time()\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      break       \n",
    "    \n",
    "    box = detectAndDisplay(img)\n",
    "    cv2.imshow('autocrop', img)\n",
    "\n",
    "    # 객체 검출될 시\n",
    "    if len(box) > 0:\n",
    "        x = box[0][0]\n",
    "        y = box[0][1]\n",
    "        w = box[0][2]\n",
    "        h = box[0][3]\n",
    "        notcnt = 0\n",
    "        if case_not > 0:\n",
    "            case_not-=1\n",
    "\n",
    "        x_ = int((2*x-w) / 2)\n",
    "        y_ = int((2*y-h) / 2)\n",
    "        w_ = int(2*w)\n",
    "        h_ = int(2*h)\n",
    "\n",
    "        if x_ <= 0: x_ = 0\n",
    "        if y_ <= 0: y_ = 0\n",
    "\n",
    "        xw = x_ + w_\n",
    "        yh = y_ + h_\n",
    "\n",
    "        if xw >= Gww: \n",
    "            xw = Gww\n",
    "        if yh >= Ghh: \n",
    "            yh = Ghh\n",
    "\n",
    "        X_min.append(x)\n",
    "        X_max.append(x+w)\n",
    "        Y_min.append(y)\n",
    "        Y_max.append(y+h)\n",
    "        \n",
    "        image = img[:, x+(w//2)-200:x+(w//2)+200]\n",
    "    else:\n",
    "        image = img[:, 440:840]\n",
    "\n",
    "    j+=1\n",
    "    \n",
    "    cv2.imshow('autocrop', image)\n",
    "    \n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbc6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0af078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
